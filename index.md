---
permalink: /
layout: singlehome
title: "Hello!"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

**You can call me Leo! I make machines that speak, sing, play, and hear.**

I am a researcher in the intersection of Artificial Intelligence and Audio, with a solid background in signal processing. Currently, I am a Junior Speech Researcher @CPqD working with Automatic Speech Recognition (ASR) and a Master’s candidate @UNICAMP.

## Interests
My research interests are aimed at developing audio‑based human‑machine interaction systems that are more affective and human‑empowering in topics such as: 

* Text-to-Speech (TTS), Text-to-Audio (TTA)
* Automatic Speech Recognition (ASR), Speaker Diarization (SD)
* Voice Conversion (VC), Singing Voice Conversion (SVC)
* Speech Emotion, Age and Gender Recognition
* Music Generation/Classification, Neural Audio Effects

I am also a hobbyist music producer, composer, and multi‑instrumentalist.

## Skills
  * **Deep Learning**: PyTorch, Tensorflow, Sci-Kit, HuggingFace, ONNX, Gradio
  * **Audio Frameworks**: Amphion, Coqui, SpeechBrain, ESPNET, NeMo
  * **Tools**: Docker, Git
  * **Programming**: Python, C, C++, MATLAB, LaTeX
  * **Cloud**: AWS, GCP
  * **Languages**: Portuguese, English, French
  * **Competences**: Paper Implementation, Experiment Design, Team Collaboration

## Work Experience
**(2023-Current) - Junior Speech Researcher [@CPqD](https://www.linkedin.com/company/cpqd/)**
  * Enriched the company’s call center customer profiling product by developing and sending to production speech age and gender classifier models.
  * Improved the company’s emotion recognition system in production, in terms of speed and performance, by developing a 2‑step emotion recognition architecture (ECAPA‑TDNN to filter out neutral speech + WavLM Emotion Classifier).
    
**(2021-2023) - Fellow Master [@CPqD](https://www.linkedin.com/company/cpqd/)**
  * Developed neural customer‑oriented expressive speech synthesis models for the Brazilian Portuguese language.
  * Enabled customers to edit the synthesized audios’ prosody in a fine‑grained way by implementing character‑level prosody control graph
pipelines on the ONNX version of the FastPitch TTS model.
  * Conducted several subjective perceptual experiments to evaluate synthetic audio quality and naturalness.
    
**(2020-2021) - Lab Intern @LPS**
  * Enhanced lab automation by designing neural speech commands recognition systems.
  * Encapsulated the ASR system in a local private LoRa network for IoT purposes.
  * Enabled long distance voice control by developing a wearable prototype with an embedded microphone.
    
## Education
(2024) M.Sc. Computer Engineering @UNICAMP

(2021) B.Sc. Electronic Engineering @UFPB

(2019) Excellence Exchange Student @Télécom Paris
